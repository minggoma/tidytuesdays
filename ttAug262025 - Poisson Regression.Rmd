---
title: "tt07Oct2025"
author: "AM"
date: "2026-02-25"
output: html_document
---

# Intro
I wanted to do a Tidy Tuesday dataset that had some sort of a count variable, since I wanted to practice Poisson regression. Luckily for me, there was this dataset, with a measure of the number of weeks at number one, and a whole slew of different variables. 

The goal of this Tidy Tuesday effort will be to clean the data, then explore all of the variables (I want to challenge myself to see if I can do this in an efficient way), and then do a Poisson regression. 

My plan of attack is as follows:
1. Clean the data
2. Explore the data, find variables that may have a relationship with outcome
3. Check my model assumptions
4. Fit the model
5. Check measure of goodness-of-fit of the model

```{r}
tuesdata <- tidytuesdayR::tt_load('2025-08-26')

bb <- tuesdata$billboard
topics <- tuesdata$topics

library(tidyverse)
library(ggplot2)
library(ggsignif)

```
## Cleaning the Data
This dataset has 105 variables - quite a lot. Some of the data can be grouped into general buckets, such as data on the artist, data on the producer, data on the song itself, etc. I'll break up my data cleaning efforts into those major chunks for my own ease. 

The goal for the data cleaning is to convert variables to their correct data type, factorize any dummy variables, combine any variables needed to make the data set tidy, and see if any variables have a large number of missing values. 

I'll write a function below that will return the proportion of values that are NA for a given vector of column names.
```{r}
#-----------------------------------------------------------------------------#
# Function Name: propna()
# Arguments:
#   df - a data frame
#   colvec - a list of column names in df
# Returns: a matrix where the second column is the proportion of NA values in
#   a given column
# Description: Intended for use in data cleaning. Returns the proportion of NA
#   values in a given column within a matrix
#-----------------------------------------------------------------------------#


propna <- function(df, colvec){
    
    #Subset the data frame
    d <- df[, colvec]
    
    #Initialize vector to hold proportions
    props <- c()
    
    for(i in 1:length(colvec)) {
        
        nas <- sum(is.na(d[, i])) / nrow(d)
        
        props <- c(props, nas)
    }
    
    #Return the proportions binded to column names
    return(cbind(colvec, props))
}
```

I'll also write a function to check for any negative values or for any extremely large values for any numeric variables, to check for any potential data entry errors.
```{r}
#-----------------------------------------------------------------------------#
# Function Name: negorout_ind()
# Arguments:
#   vec - a numeric vector
# Returns: a vector of equal length to vec
# Description: Parses through every value of vec. If a value of vec is 0 or 
#   more than 5 standard deviations from the mean, will assign a value of 1
#   to that index in the return vector. Intended for use in negorout()
#-----------------------------------------------------------------------------#

negorout_ind <- function(vec){
    
    #Calculate mean and sd to check outliers
    avg <- mean(vec, na.rm = TRUE)
    std <- sd(vec, na.rm = TRUE)
    
    #Initialize vector for return
    temp <- c()
    
    for(i in 1:length(vec)){
    
        
        #If value is NA, its not negative or an outlier
        if(is.na(vec[i])) {temp <- c(temp, 0)}
        
        #Assign value of 1 if a value is negative or outlier
        else if(vec[i] < 0 | vec[i] > (avg + 5*std)) {temp <- c(temp, 1)}
        
        #Assign value of 0 otherwise
        else{temp <- c(temp, 0)}
        
        #Continuously add values into the vector
    }
    
    
    #Return vector of same length as nrow(df)
    return(temp)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: negorout()
# Arguments:
#   df - a data frame
#   colvec - a vector of column names in df
# Returns: a matrix of indices where a value is negative or an outlier
# Description: Parses through every column in colvec in df. Applies the function
#   negorout_ind() to determine if any values are negative or outliers. Returns
#   a matrix that contains vectors of indices for negative or outlier values
#   for a given variable
#-----------------------------------------------------------------------------#
negorout <- function(df, colvec){
    
    #Subset data frame
    d <- df[, colvec]
    
    #Initialize empty vector for return
    ret <- c()
    
    for(i in 1:length(colvec)){
        
        #Only progress if column is numeric
        if(is.numeric(d[, i][[1]])){

            sumvec <- negorout_ind(d[, i][[1]])
            
            #If any value is an outlier or negative, cbind the vector
            if(sum(sumvec, na.rm = TRUE) > 0){
                
                ret <- cbind(ret, sumvec) 
                
                #Rename the right-most column to be equal to the variable name
                colnames(ret)[ncol(ret)] <- colvec[i]
                }
            else{}
            
        }
        #If column is not numeric, do nothing
        else{}
    }
    
    return(ret)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: checknegorout()
# Arguments:
#   df - a data frame
#   m - a matrix returned by negorout()
# Returns: a list of vectors containing values identified as negative or outlier
# Description: Uses the matrix returned by negorout() to subset the vector
#   and show the actual values that are being flagged as negatives or outliers.
#-----------------------------------------------------------------------------#
checknegorout <- function(df, m) {
    
    #Initialize empty list to return
    lst <- list()
    
    for(i in 1:ncol(m)){
        
        #Create a boolean vector that is true at indices for neg / outliers
        outlierindices <- which(m[, i] == 1)
        
        #Subset the vector based on the boolean vector
        vec <- bb[, colnames(m)[i]][[1]][outlierindices]
        
        #Add the variable name to the front of the vector
        #It's not pretty, but it works
        vec <- c(colnames(m)[i], vec)
        
        #Add the list into the list
        lst <- append(lst, list(vec))
        
    }
    
    return(lst)
}
```


```{r}
#-----------------------------------------------------------------------------#
# Function Name: checkzeroorone()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a vector of variable names that have values other than 0 or 1
# Description: This function is intended to be used only to check dummy 
#   variables with values of 0 or 1. It subsets the variable vector to only
#   include values that have values other than 0 or 1, and if the length of this
#   vector is greater than 0, it returns the name of the vector
#-----------------------------------------------------------------------------#
checkzeroorone <- function(df, vec){
    #Subset the vector
    d <- df[, vec]
    
    #Initialize return vector
    ret <- c() 
    for(i in 1:length(vec)) {
        
        #Store subsetted vector with values other than 0 or 1
        check <- d[, i][!(d[, i] == 0 | d[, i] == 1)]
        
        #If vector has any values, add variable name to returned vector
        if(length(check) > 0){
            ret <- c(ret, names(d)[i])
        }
        else{}
    }
    
    return(ret)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: checkzerototwo()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a vector of variable names that have values other than 0 or 3
# Description: This function is intended to be used only to check dummy 
#   variables with values of 0 or 3. It subsets the variable vector to only
#   include values that have values other than 0 or 3, and if the length of this
#   vector is greater than 0, it returns the name of the vector
#-----------------------------------------------------------------------------#
checkzerototwo <- function(df, vec){
    #Subset the vector
    d <- df[, vec]
    
    #Initialize return vector
    ret <- c() 
    for(i in 1:length(vec)) {
        
        #Store subsetted vector with values other than 0 or 1
        check <- d[, i][!(d[, i] == 0 | 
                              d[, i] == 1 |
                              d[, i] == 2)]
        
        #If vector has any values, add variable name to returned vector
        if(length(check) > 0){
            ret <- c(ret, names(d)[i])
        }
        else{}
    }
    
    return(ret)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: checkzerotothree()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a vector of variable names that have values other than 0 or 3
# Description: This function is intended to be used only to check dummy 
#   variables with values of 0 or 3. It subsets the variable vector to only
#   include values that have values other than 0 or 3, and if the length of this
#   vector is greater than 0, it returns the name of the vector
#-----------------------------------------------------------------------------#
checkzerotothree <- function(df, vec){
    #Subset the vector
    d <- df[, vec]
    
    #Initialize return vector
    ret <- c() 
    for(i in 1:length(vec)) {
        
        #Store subsetted vector with values other than 0 or 1
        check <- d[, i][!(d[, i] == 0 | 
                              d[, i] == 1 |
                              d[, i] == 2 |
                              d[, i] == 3)]
        
        #If vector has any values, add variable name to returned vector
        if(length(check) > 0){
            ret <- c(ret, names(d)[i])
        }
        else{}
    }
    
    return(ret)
}
```


```{r}
#-----------------------------------------------------------------------------#
# Function Name: factorize()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a data frame identical to df with all the listed variables factorized
# Description: applies factor() function to all variables listed in vec
#-----------------------------------------------------------------------------#

factorize <- function(df, vec){
    
    for(i in 1:length(vec)) {
        
        df[, vec[i]][[1]] <- factor(df[, vec[i]][[1]])
    }
    
    return(df)
}
```

### Section 1

Looking at the data dictionary that's provided on the [Tidy Tuesday github page](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-08-26/readme.md) for this data set, it looks like basically everything is the right data type, with no dummy variables. As seen below, the proportion of NA values for this chunk is very low. 
```{r}
#List of column names for this chunk
c1 <- names(bb)[1:16]

head(bb %>% select(all_of(c1)), 10)
```

Examining the proportion of NA values, we see that the number of NA values in each column is relatively small. 
```{r}
propna(bb, c1)
```

Additionally, we see that only one column has an outlier or negative value - the variable for number of weeks at the number one ranking. 
```{r}
m <- negorout(bb, c1)

dim(m)

colnames(m)
```
When we examine which value that is:
```{r}

outlierindices <- which(m[, 1] == 1)

bb$weeks_at_number_one[outlierindices]
```
We see that 2 songs were held the top spot for 19 weeks. These songs were:
```{r}
bb$song[outlierindices]
```
Hilariously, I have heard both of these songs. It's interesting because these are both songs that were released within the past 10 years, and both had a very strong presence on TikTok specifically. Fortunately, there is a variable in this dataset that is somewhat related to that (associated_with_dance).

This chunk looks relatively good - it has few NA values, data is already the correct type, and the few outliers that are in this chunk look reasonable and plausible. The only other thing I'd like to do is generate a year variable and a generation variable. The reason I want to do this is because I have a theory that some of the variability in what kinds of songs that rise to the Billboard Top 100 number 1 spot are dependent on the generation. Baby boomers tend to have different music tastes than Gen Alpha, and I think this should be accounted for in the model. The easiest way to do this, in my opinion, is to increment the years into a variable that represents the generation that is dominating the entry-level workforce. For example, right now, that would be Gen Z - which, understandably, listens to songs like Old Town Road and A Bar Song (and apparently, they listen to them a lot). My theory is there is an interaction term with the generation and the genre - Boomers grew up on rock and roll, Gen Z grew up on post-ironic-post-modern rap. 

First, I'll extract the year from the date variable using the year() function, and then use case_when() to create different generations based on the years. The dates span from 1958 to 2025. I'm using [this](https://en.wikipedia.org/wiki/Generation#/media/File:Generation_timeline.svg) reference for the definition of generations in the Western world, and then I'll shift the years by 22 to match when these generations enter what I consider their peak years of cultural influence. 
```{r}
library(lubridate)


bb <- bb %>% mutate(generation = case_when(
    year(date) > 1940 & year(date) <= 1967 ~ "Silent Generation",
    year(date) > 1968 & year(date) <= 1986 ~ "Baby Boomers",
    year(date) > 1987 & year(date) <= 2002 ~ "Generation X",
    year(date) > 2003 & year(date) <= 2018 ~ "Millennials",
    year(date) > 2019 ~ "Gen Z",
    TRUE ~ NA
))

propna(bb, c("generation"))
```

You're welcome to disagree with me on how I've cut up the generations if you want. But the most popular song on June 6, 2008 was Viva La Vida by Coldplay. If you're telling me that's not firmly a Millennial anthem, I'm not really sure what to tell you.

One final thought for this section is how to handle repeat songs.

```{r}
length(unique(bb$song)) < nrow(bb)
```
As seen above, there are clearly repeats of song names. When we examine what songs these are and when they hit the charts
```{r}
bb %>% filter(song %in% bb[duplicated(bb$song), ]$song) %>% arrange(song)
```
Some of these are just songs that happen to have common titles - I have to imagine "Wild Wild West" by The Escape Club is slightly different from "Wild Wild West" by Will Smith ft. Dru Hill & Kool Moe Dee. Just a hunch. I'm electing to not remove any duplicate songs for now.


### Section 2
This section contains information mostly about the artist and the producer. There are a few dummy variables that I will factorize after checking the data quality. I won't write as much as I did above, partially since it's getting a little tiring for me, and partially because you've seen what I'm doing.
```{r}
c2 <- names(bb)[17:39]

propna(bb, c2)

#TODO: Remove Featured Artists and Talent Contestant

m <- negorout(bb, c2)

ncol(m)

#4 columns with outliers

colnames(m)

#The group named after non-lead singer value is mostly 0
#Anything with a value of 1 is getting flagged as an outlier, I'm not concerned
bb$group_named_after_non_lead_singer[which(m[, 1] == 1)]

#Same with posthumous - value is almost always 0
bb$posthumous[which(m[, 2] == 1)]

#Apparently someone was 78 when their song hit #1
bb$front_person_age[which(m[, 3] == 1)]

#Apparently this was Brenda Lee, whose song Rockin' Around the Christmas Tree
# released in 1958 hit the Billboard Hot 100 Number 1 in 2023. Cool! Also, she
# was alive to see it happen. Also cool!
bb[which(m[, 3]==1), ]

#Dummy variable which is intended to have values of 0, 1, 2, or 3
#Value of 3 is just rare, not concerning
bb$producer_male[which(m[, 4] == 1)]
```

Now I need to factorize all the dummy variables. While the function to check for negative values or outliers is helpful, I also want to make sure that only the correct levels are included for each variable. 
```{r}
#Choose the variables that are dummy variables
dummy01 <- c("multiple_lead_vocalists", "group_named_after_non_lead_singer",
             "posthumous", "artist_is_a_songwriter", "artist_is_only_songwriter",
             "artist_is_a_producer", "artist_is_only_producer", 
             "songwriter_is_a_producer")
dummy02 <- c("artist_white", "artist_black", "songwriter_white", 
             "producer_white")
dummy03 <- c("artist_male", "songwriter_male", "producer_male")

checkzeroorone(bb, dummy01)
checkzerototwo(bb, dummy02)
checkzerotothree(bb, dummy03)

#All values look good - now can factorize

dummy <- c(dummy01, dummy02, dummy03)
bb <- factorize(bb, dummy)
```

The only other thing I want to do is combine artist_white and artist_black into one variable - artist_race. I'm doing this because these variables are both related to artist race and are mutually exclusive - an artist cannot be both white and black. I've double checked this below - there are no entries where both artist_white and artist_black are both 1 for the same observation.

```{r}
bb %>% filter(artist_white == 1 & artist_black == 1) %>% nrow()

bb <- bb %>% mutate(artist_race = case_when(
    artist_white == 1 ~ 1,
    artist_black == 2 ~ 2, 
    TRUE ~ 3, #To represent mixed race(s)
))

bb$artist_race <- factor(bb$artist_race)
```


### Section 3

Everything between the previous section and the section after this, which is all dummy variables for whether an instrument appears in a song. 
```{r}
c3 <-names(bb)[40:48]

bb %>% select(all_of(c3)) %>% head()

#Loudness is all negative, I'll just check for outliers by hand

#Very few NA values
propna(bb, c3)

#Remove loudness since it's all negative values
negorout(bb, c3[-8])
#No negative or outlier values

#Looks like there are some extreme values, but seems reasonable and possible
boxplot(bb$loudness_d_b)
```

```{r}
#Just some extra EDA
g <- ggplot(data = bb, aes(x = time_signature)) + geom_bar() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
#Over 90% of songs are in 4/4, I'm not going to clean this data further
g

g <- ggplot(data = bb %>% group_by(keys) %>% summarize(count = n()) %>% filter(count > 5), 
            aes(x = keys, y = count)) + geom_col() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
g

#Surprised that so many songs in the minor key are in here
#I'll make a variable for major or minor key

grepl("m", bb$keys)

bb <- bb %>% mutate(major_or_minor = case_when(
    
    #Ends in a minor key
    grepl("m$", keys) ~ "minor",
    
    is.na(keys) ~ NA,
    TRUE ~ "major"
))

#TODO: Create a variable for key by frequency?

g <- ggplot(data = bb, aes(x = major_or_minor)) + geom_bar()
g
```
Factorizing the appropriate variables from this section:
```{r}
bb$major_or_minor <- factor(bb$major_or_minor)

```

### Section 4

```{r}
c4 <- names(bb)[49:73]

propna(bb, c4) #Wow. All values for all variables

m1 <- negorout(bb, c4) #16 variables have at least one negative value or outlier
                      #Use a function to figure out what each value is

checknegorout(bb, m) #All values are 1, indicating that 1 is an outlier
                     #These instruments are likely so rare

#Confirm with histograms

par(mfrow = c(4, 4),
    mar = c(4, 4, 2, 1),
    oma = c(0, 0, 2, 0))

with(bb, {
    
    for(i in 1:ncol(m1)){
        
        #Plot a histogram
        hist(bb[, colnames(m1)[1]][[1]], main = colnames(m1)[i], xlab = "")
        
    }
})

#All of these plots have very few 1s 

#TODO: Delete this columns since they won't add anything to the analysis
```
These are all dummy variables, which should have values 0 or 1. I'll use a function to quickly parse through and see if any have values that are not zero or one
```{r}
checkzeroorone(bb, names(bb)[49:73])

#Nice, all zeros or ones

bb <- factorize(bb, names(bb)[49:73])
```
### Section 5
```{r}
c5 <- names(bb)[74:94]

propna(bb, c5)
#Sound effects has 94% of values as NA - NA likely represents no sound effects
#TODO: Remove sound_effects since it's not doing much for me
#Remaining columns are all relatively NA free

m <- negorout(bb, c5)

colnames(m)

checknegorout(bb, m)
#Some of these look like they're outliers because they have values of either
# 0 or 1, and 1 is just rare

#Others seem like they might be actual outliers, specifically for song length
# and intro length

hist(bb$rap_verse_in_a_non_rap_song)
summary(bb$rap_verse_in_a_non_rap_song) # 1 is just a rare value

hist(bb$length_sec)
bb %>% filter(length_sec > 500) %>% head()
#After googling, both of these songs and their lengths are correct

hist(bb$instrumental)
summary(bb$instrumental) #1 is just a rare value

hist(bb$instrumental_length_sec)
bb %>% filter(instrumental_length_sec > 200) %>% 
    select(song, artist, instrumental_length_sec) %>% head()

#335 seconds is "Fly, Robin, Fly" which has only 6 words - "Fly, Robin, Fly,
# up, up to the sky." Why this was the number 1 song at any point is beyond me

#254 seconds is "The Hustle" by Van McCoy, which actually kind of slaps
#The other songs with long instrumentals also look correct

hist(bb$intro_length_sec)
bb %>% filter(intro_length_sec > 100) %>% 
    select(song, artist, intro_length_sec) %>% head()

#"Theme from Shaft" is truly 109 seconds of an intro
#"Papa Was a Rollin' Stone" is also 115 seconds of an intro
# Both look correct

hist(bb$free_time_vocal_introduction)
summary(bb$free_time_vocal_introduction) # 1 is just a rare value

hist(bb$foreign_language)
summary(bb$foreign_language) # 1 is just a rare value

#Checked all outliers / negative values, looks good to me

#Need to check all factor levels

dummy <- c5[-c(1, 2, 4, 6, 7, 16, 17)]

checkzeroorone(bb, dummy) #everything has a value of 0 or 1

bb <- factorize(bb, dummy)

#TODO: Think more about song structure - should I factorize?
```


### Section 6

I grouped off this section of variables since I feel like it has a lot to do with media:
```{r}
c6 <- names(bb)[95:105]

propna(bb, c6)

#The "featured_in" variables are almost all NA
#NA likely represents that it was not featured in a piece of media

m <- negorout(bb, c6)
colnames(m)

checknegorout(bb, m)

#The unusual values are all 1, likely indicating that the value is rare
#Check each individually

hist(bb$written_for_a_play)
summary(bb$written_for_a_play)

hist(bb$written_for_a_t_v_show)
summary(bb$written_for_a_t_v_show)

hist(bb$associated_with_dance)
summary(bb$associated_with_dance)

hist(bb$topped_the_charts_by_multiple_artist)
summary(bb$topped_the_charts_by_multiple_artist)

hist(bb$eurovision_entry)
summary(bb$eurovision_entry)

#All the "outlier" values are reasonable
```
I think that, particularly for more recent years, having a song be written for or featured in a piece of media has a large impact. However, the issue with this data is that it's so spread out - there are very few entries for being featured in a movie, for being featured in a play, etc. I'm going to combine them all into one variable called media to indicate if they were written for or featured in a piece of popular media at the time. 

First, I'll convert all of the character variables into dummy variables to indicate whether or not they were featured in a piece of media, rather than what piece of media they were featured in, since that will be more helpful for our analysis
```{r}
bb <- bb %>% mutate(featured_in_a_then_contemporary_play = case_when(
    !is.na(featured_in_a_then_contemporary_play) ~ 1,
    TRUE ~ 0
))

bb <- bb %>% mutate(featured_in_a_then_contemporary_film = case_when(
    !is.na(featured_in_a_then_contemporary_film) ~ 1,
    TRUE ~ 0
))

bb <- bb %>% mutate(featured_in_a_then_contemporary_t_v_show = case_when(
    !is.na(featured_in_a_then_contemporary_t_v_show) ~ 1,
    TRUE ~ 0
))

#Combine them all into a featured variable

bb <- bb %>% mutate(featured = case_when(
    (featured_in_a_then_contemporary_play == 1 |
         featured_in_a_then_contemporary_film == 1 |
         featured_in_a_then_contemporary_t_v_show == 1) ~ 1,
    TRUE ~ 0
))

#Check that the written_for variables have only 0 or 1
checkzeroorone(bb, c("written_for_a_play", "written_for_a_film", 
                     "written_for_a_t_v_show"))

#Create a combined written_for variable

bb <- bb %>% mutate(written_for = case_when(
    (written_for_a_play == 1 |
         written_for_a_film == 1 |
         written_for_a_t_v_show == 1) ~ 1,
    TRUE ~ 0
))

#Create a combined media variable
bb <- bb %>% mutate(media = case_when(
    featured == 1 | written_for_a_play == 1 ~ 1,
    TRUE ~ 0
))

#Check the remaining factor variables
checkzeroorone(bb, c("associated_with_dance", "topped_the_charts_by_multiple_artist",
                     "double_a_side", "eurovision_entry"))

#Double A side is not 0 or 1
table(bb$double_a_side) #Ah. It lists the song name. Which is stated in the dd

#Factorize all relevant variables

bb <- factorize(bb, c("associated_with_dance", "topped_the_charts_by_multiple_artist",
                "eurovision_entry", "generation", "featured", "written_for", 
                "media"))
```

Ok. All of my data is clean now. I'm now going to remove any columns that I've flagged with TODOs since they're not going to add any value to my data analysis.

The list of variables I'm going to remove is:
- featured_artists
- talent_contestant
- all of those random instruments (contained in negorout(bb, c4))
- sound effects
- featured_in_a_then_contemporary_play
- featured_in_a_then_contemporary_film
- featured_in_a_then_contemporary_t_v_show
- written_for_a_play
- written_for_a_film
- written_for_a_t_v_show
- artist_white
- artist_black

```{r}

removenames <- c("featured_artists", 
                 "talent_contestant", 
                 "sound_effects",
                 "featured_in_a_then_contemporary_play", 
                 "featured_in_a_then_contemporary_film",
                 "featured_in_a_then_contemporary_t_v_show",
                 "written_for_a_play",
                 "written_for_a_film",
                 "written_for_a_t_v_show",
                 "artist_white",
                 "artist_black",
                 colnames(m1))

bb <- bb %>% select(-(all_of(removenames)))

```

# Exploratory Data Analysis
Ok. For the fun stuff now. I now need to investigate the relationship between each (or most) of these variables with the outcome of Weeks at Number 1

I'll create a vector to hold the character strings of variables I'll definitely include, and a vector to hold character strings of variables I might include:
```{r}
def <- c()
maybe <- c()

```


Starting with the ratings - there are 3 ratings from 3 judges, and the sample mean of those ratings. Let's take a look at those now:

```{r}

#Change plot to be 2x2
par(mfrow = c(2, 2))

with(bb, {hist(bb$rating_1, main = "Rating 1", xlab = "")
    hist(bb$rating_2, main = "Rating 2", xlab = "")
    hist(bb$rating_3, main = "Rating 3", xlab = "")
    hist(bb$overall_rating, main = "Overall Rating", xlab = "")
    })

```
Interestingly, it looks the median of rating 3 tends to be higher than the others. I'm actually curious if it's significantly different. I'll use the Kruskal-Wallis test since this is ordinal data rather than pure numeric data. 

```{r}
median(bb$rating_1)
median(bb$rating_3)
wilcox.test(bb$rating_3, bb$rating_1)
```
That's so interesting. Whoever Judge 3 is, they seem to be a bit nicer than Judge 1 at least.

Regardless, it looks like the overall rating is a better measure, since it follows the same distribution but is a composite of multiple ratings. 

```{r}
ggplot(data = bb, aes(x = overall_rating, y = weeks_at_number_one)) + 
    geom_point(position = "jitter", alpha = 0.3, pch = 1)  + geom_smooth(method = "lm")

cor(bb$overall_rating, bb$weeks_at_number_one, method = "spearman")
```
The relationship doesn't look as strong as I was expecting, but there's a clear non-zero trend that feels like it will explain some variability in the outcome. We should include it in our model. Pre-hoc, it seems reasonable to assume that rating is important. The Spearman correlation coefficient is low - I won't calculate them for future variables since I think the utility of using is low when I can see the relationship graphically.
```{r}
def <- c(def, "overall_rating")
```



Divisiveness is kind of interesting, I wonder what the distribution looks like:
```{r}
hist(bb$divisiveness) #Unsurprisingly, most songs are not that divisive

ggplot(data = bb, aes(x = divisiveness, y = weeks_at_number_one)) + 
    geom_point(position = "jitter", alpha = 0.3, pch = 1)  + geom_smooth(method = "lm")

```
The relationship between divisiveness and weeks at number 1 is pretty weak - I'm going to elect to not include it in my model.

I can't imagine label or parent_label are going to make a significant difference in the analysis, but I'll check regardless:
```{r}
ggplot(data = bb, aes(x = label)) + geom_bar()


#There are a few labels that are dominating, let's isolate them

bb %>% group_by(label) %>% summarize(count = n()) %>% filter(count > 5) %>% 
    arrange(desc(count))

#What does the parent_label look like?
bb %>% group_by(parent_label) %>% summarize(count = n()) %>% filter(count > 5) %>% 
    arrange(desc(count))

#It looks like label is consolidated, but parent_label is even more consolidated
#The top 5 parent labels account for almost 50% of all songs
```
The top 5 parent labels (Warner Bros, Sony, Vivendi, EMI, and CBS) account for almost 50% of all songs that have reached number 1 on the Billboard 100. I'm going to consolidate them into a variable called toplabel
```{r}
bb <- bb %>% mutate(toplabel = case_when(
    parent_label == "Warner Bros." | parent_label == "Sony" | 
        parent_label == "Vivendi" | parent_label == "EMI" |
        parent_label == "CBS" ~ 1,
    is.na(parent_label) ~ NA_real_,
    TRUE ~ 0
))

bb$toplabel <- factor(bb$toplabel)

#Writing out the whole variable name for the weeks at number 1 is annoying
#I'm going to rename it weeks

bb <- bb %>% rename(weeks = weeks_at_number_one)

ggplot(data = bb, aes(x = toplabel, y = weeks)) + geom_boxplot()


#Surprisingly, it actually doesn't seem to make that much of a difference

wilcox.test(bb$weeks ~ bb$toplabel) #Non-significant
```
The Wilcox test does not reach significance with an alpha of 0.5, but it is close. The fact that the medians are so close makes me inclined to not include this in our final model.

Let's look at genre, which I'm sure will be important:
```{r}
table(bb$cdr_genre)

#TODO: consolidate genres

table(bb$discogs_genre)

#The style variables are all very different
```
The discogs genre is much more specific, but for the purposes of grouping it into a genre variable, it's much less useful. The CDR genre variable is a bit broader, which makes it easier to group things together. We'll only include the CDR genre - I'm going to include genre in the model regardless, since I assume it has to have a strong impact on the rankings.

```{r}
table(bb$cdr_genre)
```
I can see that there are variables that have very few entries, like Polka, but other genres like Pop are well represented here. For the sake of making reasonable groups, I'll choose the 6 largest genres, and combine the rest into a fifth variable of "other" (sorry. I've recently become more partial to Folk / Country music).
```{r}
bb %>% group_by(cdr_genre) %>% summarize(count = n()) %>% arrange(desc(count))

bb <- bb %>% mutate(genre = case_when(
    cdr_genre != "Pop" & cdr_genre != "Rock" & cdr_genre != "Funk/Soul" &
        cdr_genre != "Electronic/Dance" & cdr_genre != "Hip Hop" &
        cdr_genre != "Folk/Country" ~ "Other",
    is.na(cdr_genre) ~ NA,
    TRUE ~ cdr_genre
    
))

options(repr.plot.width=20, repr.plot.height=8)

ggplot(data = bb, aes(x = genre, y = weeks)) + 
    geom_dotplot(binaxis = "y", 
                 stackdir = "center",
                 aes(fill = generation),
                 dotsize = 0.5,
                 alpha = 0.3,
                 width = 1.5,
                 binwidth = 0.5) + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

ggplot(data = bb, aes(x = genre, y = weeks)) + geom_boxplot()

#It looks like hip hop might be higher

kruskal.test(weeks ~ genre, bb) #Significant
def <- c(def, "genre")
```

Now to look at variables related to the group:
```{r}
#Whoops, forgot to factorize artist_structure
bb$artist_structure <- factor(bb$artist_structure)

ggplot(data = bb, aes(x = artist_structure, y = weeks)) + geom_boxplot()

kruskal.test(weeks ~ artist_structure, bb)
#It looks like 2.5 might be higher than the others, but it has only 8 entries
#Won't include this in the final model
```

```{r}
ggplot(data = bb, aes(x = multiple_lead_vocalists, y = weeks)) + geom_boxplot()

kruskal.test(weeks ~ multiple_lead_vocalists, bb) #Significant

maybe <- c(maybe, "multiple_lead_vocalists")
```


```{r}
ggplot(data = bb, aes(x = group_named_after_non_lead_singer, y = weeks)) + 
    geom_boxplot()


wilcox.test(weeks ~ group_named_after_non_lead_singer, bb) #Not significant
```

```{r}

ggplot(data = bb, aes(x = posthumous, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ posthumous, bb)
#No difference, won't include in model
```
Variables related to artists:
```{r}
#836 songs are from artists from the US - I'll combine variables to be US and
# non-US

bb <- bb %>% mutate(artist_us = case_when(
    artist_place_of_origin == "United States" ~ 1,
    is.na(artist_place_of_origin) ~ NA_real_,
    TRUE ~ 0
))

bb$artist_us <- factor(bb$artist_us)

ggplot(data = bb, aes(x = artist_us, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ artist_us, bb) #Not significant. A bop is a bop
```

```{r}
hist(bb$front_person_age)

ggplot(data = bb, aes(x = front_person_age, y = weeks)) + 
    geom_point(position = "jitter") + geom_smooth(method = "lm")

#The association isn't strong, but I'm concerned that the one point at age 78
# is a high leverage point. I'm going to remove and replot

ggplot(data = bb %>% filter(front_person_age < 70), 
       aes(x = front_person_age, y = weeks)) + geom_point(position = "jitter") + 
    geom_smooth(method = "lm")

#Ok still doesn't change. Won't include it in the model
```

```{r}
#artist_male
ggplot(data = bb, aes(x = artist_male, y = weeks)) + geom_boxplot()
#Unimpressive

kruskal.test(weeks ~ artist_male, bb) #Not significant
```

```{r}
#artist_race
ggplot(data = bb, aes(x = artist_race, y = weeks)) + geom_boxplot()
#Unimpressive

kruskal.test(weeks ~ artist_race, bb) #Significant, unfortunately
maybe <- c(maybe, "artist_race")
```

Think I have a groove going, but I also want to be faster. I'm going to try to do more plotting with facet wrapping to see things faster
```{r}

ggplot(data = bb %>% select(weeks, 
                            songwriter_male, 
                            songwriter_white, 
                            artist_is_a_songwriter, 
                            artist_is_only_songwriter) %>%
           pivot_longer(cols = c(songwriter_male, 
                                 songwriter_white, 
                                 artist_is_a_songwriter, 
                                 artist_is_only_songwriter),
                        names_to = "vars",
                        values_to = "vals"),
       aes(x = vals, y = weeks)) + geom_boxplot() + facet_wrap(~ vars)

kruskal.test(weeks ~ songwriter_male, bb) #Significant
kruskal.test(weeks ~ songwriter_white, bb) #Significant
kruskal.test(weeks ~ artist_is_a_songwriter, bb) #Significant
kruskal.test(weeks ~ artist_is_only_songwriter, bb) #Non-significant

maybe <- c(maybe, 
           "songwriter_male", 
           "songwriter_white", 
           "artist_is_a_songwriter")

```



```{r}
vars <- c("producer_male", "producer_white", 
          "artist_is_a_producer", "artist_is_only_producer",
          "songwriter_is_a_producer")

ggplot(bb %>% select(weeks, all_of(vars)) %>%
           pivot_longer(cols = all_of(vars),
                        names_to = "var",
                        values_to = "val"),
       aes(x = val, y = weeks)) + geom_boxplot() + facet_wrap(~var) + ylim(0, 10)

kruskal.test(weeks ~ producer_male, bb) #Not significant
kruskal.test(weeks ~ producer_white, bb) #Not significant
wilcox.test(weeks ~ artist_is_a_producer, bb) #Not significant
wilcox.test(weeks ~ artist_is_only_producer, bb) #Not significant
wilcox.test(weeks ~ songwriter_is_a_producer, bb) #Significant

maybe <- c(maybe, "songwriter_is_a_producer")
```
Explore key and major/minor:
```{r}
ggplot(data = bb, aes(x = simplified_key, y = weeks)) + geom_boxplot() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) + ylim(0, 10)

#It actually looks like Em and Gm are slightly higher

kruskal.test(weeks ~ simplified_key, bb) #Not significant. Interesting

#I think I'm still going to include this in the model because the medians do 
# look a little different, and pre-hoc I think this could affect ranking

def <- c(def, "simplified_key")
```

```{r}
ggplot(data = bb, aes(x = major_or_minor, y = weeks)) + geom_boxplot() + ylim(0, 10)

wilcox.test(weeks ~ major_or_minor, bb) #Significant

def <- c(def, "major_or_minor")
```
All the numeric variables:
```{r}
var <- c("energy",
         "danceability",
         "happiness",
         "acousticness")

ggplot(data = bb %>% select(weeks, all_of(var)) %>%
           pivot_longer(cols = all_of(var), 
                        names_to = "vars",
                        values_to = "vals"),
       aes(x = vals, y = weeks)) + geom_point() + geom_smooth(method = "lm") + 
    facet_wrap(~ vars) 

#It looks like acousticness and danceability might have a relationship

#Plot them separately to view

ggplot(data = bb, aes(x = acousticness, y = weeks)) + geom_point() + 
    geom_smooth(method = "lm")

#It looks like acousticness actually has a negative relationship with weeks
def <- c(def, "acousticness")

ggplot(data = bb, aes(x = danceability, y = weeks)) + geom_point() + 
    geom_smooth(method = "lm")

#Danceability has a positive relationship with weeks
def <- c(def, "danceability")

ggplot(data = bb, aes(x = loudness_d_b, y = weeks)) + geom_point() + 
    geom_smooth(method = "lm")


#Loudness also has a relationship with weeks
def <- c(def, "loudness_d_b")

ggplot(data = bb, aes(bpm, y = weeks)) + geom_point() + 
    geom_smooth(method = "lm")

#Surprising - bpm doesn't have an impact
```
Acousticness, danceability, and loudness all had a relationship with weeks

Now to check all the dummy variables related to how the song is based. I thought about combining these variables into one, but these variables are not mutually exclusive - i.e., a song can have a value of 1 for vocally_based and for piano_keyboard_based at the same time. 
```{r}

var <- c("vocally_based",
         "bass_based",
         "guitar_based",
         "piano_keyboard_based")

ggplot(data = bb %>% select(weeks, all_of(var)) %>%
           pivot_longer(cols = all_of(var),
                        names_to = "based",
                        values_to = "vals"),
       aes(x = vals, y = log(weeks))) + 
    geom_boxplot() + 
    facet_wrap(~based) + 
    ylim(0, 3)

#Doesn't look like there's a big difference
wilcox.test(weeks ~ vocally_based, bb) #Not significant
wilcox.test(weeks ~ bass_based, bb) #Not significant
wilcox.test(weeks ~ guitar_based, bb) #Significant
wilcox.test(weeks ~ piano_keyboard_based, bb) #Not significant

```
It's a little hard to tell if any of these categorical variables have an effect. I'm looking at the boxplots, and the medians don't seem different. Of course, there are good number of outliers - some songs are at the number 1 spot for over 10 weeks, which is 2.5 months. However, based on what I saw before, especially with the simplified_key, some variables will have meaningful differences between medians based on the group.

Intuitively, I'm not surprised that most of the categorical variables so far have not had significant findings. I can't imagine that things like whether the artist was male or their race would make a huge difference in the song. 

```{r}
vars <- c("orchestral_strings",
          "horns_winds",
          "falsetto_vocal",
          "handclaps_snaps",
          "saxophone")

ggplot(bb %>% select(weeks, all_of(vars)) %>% 
           pivot_longer(cols = all_of(vars),
                        names_to = "instruments",
                        values_to = "vals"),
       aes(x = vals, y = weeks)) + geom_boxplot() + facet_wrap(~instruments) + 
    ylim(0, 10)

#Again, no real differences

wilcox.test(weeks ~ orchestral_strings, bb) #Not significant
wilcox.test(weeks ~ horns_winds, bb) #Significant
wilcox.test(weeks ~ falsetto_vocal, bb) #Not significant
wilcox.test(weeks ~ handclaps_snaps, bb) #Not significant
wilcox.test(weeks ~ saxophone, bb) #Not significant

maybe <- c(maybe, "horns_winds")
```
Looking at song structure, it's dominated by a few song structure types (unsurprisingly). I'll keep any song structure that has over 50 entries, and then I'll combine all the rest into an "other" category

```{r}
bb <- bb %>% mutate(structure = case_when(
    song_structure == "A2" |
        song_structure == "C1" |
        song_structure == "C3" |
        song_structure == "D1" |
        song_structure == "E1" |
        song_structure == "E3" ~ song_structure,
    is.na(song_structure) ~ NA,
    TRUE ~ "Other"
))

ggplot(data = bb, aes(x = structure, y = log(weeks))) + geom_boxplot() + ylim(0, 10)
kruskal.test(weeks ~ structure, bb) #Significant

def <- c(def, "structure")

```

Rap verse in a non rap song:
```{r}

ggplot(bb, aes(x = rap_verse_in_a_non_rap_song, y = weeks)) + geom_boxplot()
#It actually looks clearly different.
#Probably the starkest visual difference on boxplot I've seen so far

wilcox.test(weeks ~ rap_verse_in_a_non_rap_song, bb) #IT'S SIGNIFICANT LMAOO

#If you want your song to stick at number one, get a rapper


#What songs even are these
#The most recent ones are a lot of Korean songs
#Butter by BTS had 10 straight weeks

def <- c(def, "rap_verse_in_a_non_rap_song")

```
Song Length: I could see shorter songs doing better on the charts
```{r}

ggplot(bb, aes(x = length_sec, y = weeks)) + 
    geom_point(position = "jitter",
               alpha = 0.3) + 
    geom_smooth(method = "lm")

#I'm concerned that some of the outliers are high leverage points

ggplot(bb %>% filter(length_sec < 500), aes(x = length_sec, y = weeks)) + 
    geom_point(position = "jitter",
               alpha = 0.3) + 
    geom_smooth(method = "lm") #It looks there's a positive relationship

def <- c(def, "length_sec")

```
Instrumental:
```{r}

ggplot(bb, aes(x = instrumental, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ instrumental, bb) #Non significant

#It looks like the medians could be different, but there were only 24
# songs with instrumentals, so the sample size is a bit small. May have reached
# significance with a larger sample size

maybe <- c(maybe, "instrumental")

```
Instrumental Length:
```{r}
ggplot(bb, aes(x = instrumental_length_sec, y = weeks)) + 
    geom_point(position = "jitter") + 
    geom_smooth(method = "lm")

cor(bb$instrumental_length_sec, bb$weeks, method = "spearman")

#Surprisingly strong correlation - will include in model

def <- c(def, "instrumental_length_sec")
```

Introduction Length:
```{r}
ggplot(bb, aes(x = intro_length_sec, y = weeks)) + 
    geom_point(position = "jitter") + 
    geom_smooth(method = "lm")

#Unimpressive, won't include in the model
```
Vocal Introduction:
```{r}

ggplot(bb, aes(x = vocal_introduction, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ vocal_introduction, bb) #Significant

#I'm surprised, I thought a vocal introduction might make it less likely

def <- c(def, "vocal_introduction")
```
Free Time Vocal Introduction:
```{r}

ggplot(bb, aes(x = free_time_vocal_introduction, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ free_time_vocal_introduction, bb) #Significant

#I think this variable and vocal_introduction are similar and will account for
# similar variability in the outcome

#I'll include vocal_introduction and exclude this one

```
Fade out:
```{r}

ggplot(bb, aes(x = fade_out, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ fade_out, bb) #Significant

#Interestingly significant. I'll include 

def <- c(def, "fade_out")
```

Live
```{r}

ggplot(bb, aes(x = live, y = weeks)) + geom_boxplot()

#Only 7 entries that were live - won't include

```
Cover:
```{r}

ggplot(bb, aes(x = cover, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ cover, bb) #Not significant

```

Samples:
I think this will actually be highly related to the hip hop genre, since most hip hop songs have samples of other songs (like Kanye West)
```{r}

ggplot(bb, aes(x = sample, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ sample, bb) #Significant

xtabs(~ sample + genre, data = bb)
#As expected, hip hop has the highest proportion of samples

#I will include this in the model, but I'll check for multicollinearity with and
# without this variable, since I think it's mostly related to hip hop

#TODO: Check VIF with and without sample

def <- c(def, "sample")
```

Interpolation:
```{r}

ggplot(bb, aes(x = interpolation, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ interpolation, bb) #Not significant

```

Inspired by a different song:

```{r}
ggplot(bb, aes(x = inspired_by_a_different_song, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ inspired_by_a_different_song, bb) #Almost significant

#Consider adding

maybe <- c(maybe, "inspired_by_a_different_song")

```
Lyrical Narrative:
```{r}

ggplot(bb, aes(x = lyrical_narrative, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ lyrical_narrative, bb) #Not significant

```
Spoken Word:
```{r}
ggplot(bb, aes(x = spoken_word, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ spoken_word, bb) #Not significant
```

Explicit:
I have to imagine this has an impact, no?
```{r}
ggplot(bb, aes(x = explicit, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ explicit, bb) #Significant

def <- c(def, "explicit")
```
Foreign language:
Also have to imagine that this will be important
```{r}
ggplot(bb, aes(x = foreign_language, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ foreign_language, bb) #Not significant

#A bop remains a bop
```
Associated with dance:
Again, I think this is associated with generation - more of the songs for Gen Z become popular on tik tok
```{r}

ggplot(bb, aes(x = associated_with_dance, y = weeks)) + geom_boxplot()

wilcox.test(weeks ~ associated_with_dance, bb) #Not significant

xtabs(~ generation + associated_with_dance, bb)
#About 10% of songs released in this generation have a dance associated with it

#If I control for generation, then I think that it will explain the variability
# that would be explained by this as well
```
Media
```{r}
ggplot(bb, aes(x = media, y = weeks)) + geom_boxplot()
wilcox.test(weeks ~ media, bb) #Not significant
```
Let's examine the variables I know I'm going to include in the model:
```{r}
def
```

Let's examine the variables I'm considering including in the model:
```{r}
maybe
```
The list of variables I'm definitely going to include matches pretty well with the ones I would have chosen pre-hoc. There are 15 variables, which already is a lot. Additionally, there are 9 more variables I'm considering adding. Some of these were based on the fact that the wilcox rank sum test or Kruskal Wallis test were significant. Of course, I ran many comparisons - if I ran around 100 comparisons, I would expect 5 of the tests to show significance just by chance. Based off of that, I'm okay with not including variables that don't make a lot of sense to include without the significance test results - these would be horns_winds, songwriter_male, and songwriter_white. I wouldn't normally expect that horns or winds being included in a song to have a strong impact on its ranking as number one, especially if instruments like guitar or piano which are significantly more popular were not significant. 

Also, I'm doubtful that the demographics of the songwriter impact the ranking. I think the songwriter overlaps heavily with the artist - 771 songs have the artist as a songwriter. I don't know the songwriter for the vast majority of the songs I've listened to if it's not the artist themselves. 

The inspired_by_a_different_song is an interesting one - it did not reach significance, but at the same time, I could see how building off a different popular song would be helpful. However, given the number of variables I already have in the model, I think I can afford to not include this one. 

The big ones left are multiple_lead_vocalists, artist_race, and instrumental. Multiple lead vocalists is interesting - it is possible that groups, particularly new Kpop boy bands with various talents with dancing, singing, and rapping, are more successful than individual groups. That's one I think I'll leave in.

Artist_race is also interesting - I don't deny that it could be a factor. But given that none of the other artist demographics were significant, I don't think I'll include it. I want to choose to believe that it doesn't make a big difference. 

Instrumental I also think I'll leave out - I think a lot of the variability explained by this will also be captured in the instrumental_length_sec variable.

This means that my final group of variables will be as follows:
```{r}
def <- c(def, "multiple_lead_vocalists")

#Add the other variables I'd like to keep
save <- c("song", "artist", "date", "weeks", "generation", def)

#Create a new data frame that is the clean data frame subsetted with the 
# above variables

write.csv(bb %>% select(all_of(save)), file = "billboard_clean.csv")
```


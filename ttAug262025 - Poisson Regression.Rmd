---
title: "tt07Oct2025"
author: "AM"
date: "2026-02-25"
output: html_document
---

# Intro
I wanted to do a Tidy Tuesday dataset that had some sort of a count variable, since I wanted to practice Poisson regression. Luckily for me, there was this dataset, with a measure of the number of weeks at number one, and a whole slew of different variables. 

The goal of this Tidy Tuesday effort will be to clean the data, then explore all of the variables (I want to challenge myself to see if I can do this in an efficient way), and then do a Poisson regression. 

My plan of attack is as follows:
1. Clean the data
2. Explore the data, find variables that may have a relationship with outcome
3. Check my model assumptions
4. Fit the model
5. Check measure of goodness-of-fit of the model

```{r}
tuesdata <- tidytuesdayR::tt_load('2025-08-26')

bb <- tuesdata$billboard
topics <- tuesdata$topics

library(tidyverse)
library(ggplot2)

```
## Cleaning the Data
This dataset has 105 variables - quite a lot. Some of the data can be grouped into general buckets, such as data on the artist, data on the producer, data on the song itself, etc. I'll break up my data cleaning efforts into those major chunks for my own ease. 

The goal for the data cleaning is to convert variables to their correct data type, factorize any dummy variables, combine any variables needed to make the data set tidy, and see if any variables have a large number of missing values. 

I'll write a function below that will return the proportion of values that are NA for a given vector of column names.
```{r}
#-----------------------------------------------------------------------------#
# Function Name: propna()
# Arguments:
#   df - a data frame
#   colvec - a list of column names in df
# Returns: a matrix where the second column is the proportion of NA values in
#   a given column
# Description: Intended for use in data cleaning. Returns the proportion of NA
#   values in a given column within a matrix
#-----------------------------------------------------------------------------#


propna <- function(df, colvec){
    
    #Subset the data frame
    d <- df[, colvec]
    
    #Initialize vector to hold proportions
    props <- c()
    
    for(i in 1:length(colvec)) {
        
        nas <- sum(is.na(d[, i])) / nrow(d)
        
        props <- c(props, nas)
    }
    
    #Return the proportions binded to column names
    return(cbind(colvec, props))
}
```

I'll also write a function to check for any negative values or for any extremely large values for any numeric variables, to check for any potential data entry errors.
```{r}
#-----------------------------------------------------------------------------#
# Function Name: negorout_ind()
# Arguments:
#   vec - a numeric vector
# Returns: a vector of equal length to vec
# Description: Parses through every value of vec. If a value of vec is 0 or 
#   more than 5 standard deviations from the mean, will assign a value of 1
#   to that index in the return vector. Intended for use in negorout()
#-----------------------------------------------------------------------------#

negorout_ind <- function(vec){
    
    #Calculate mean and sd to check outliers
    avg <- mean(vec, na.rm = TRUE)
    std <- sd(vec, na.rm = TRUE)
    
    #Initialize vector for return
    temp <- c()
    
    for(i in 1:length(vec)){
    
        
        #If value is NA, its not negative or an outlier
        if(is.na(vec[i])) {temp <- c(temp, 0)}
        
        #Assign value of 1 if a value is negative or outlier
        else if(vec[i] < 0 | vec[i] > (avg + 5*std)) {temp <- c(temp, 1)}
        
        #Assign value of 0 otherwise
        else{temp <- c(temp, 0)}
        
        #Continuously add values into the vector
    }
    
    
    #Return vector of same length as nrow(df)
    return(temp)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: negorout()
# Arguments:
#   df - a data frame
#   colvec - a vector of column names in df
# Returns: a matrix of indices where a value is negative or an outlier
# Description: Parses through every column in colvec in df. Applies the function
#   negorout_ind() to determine if any values are negative or outliers. Returns
#   a matrix that contains vectors of indices for negative or outlier values
#   for a given variable
#-----------------------------------------------------------------------------#
negorout <- function(df, colvec){
    
    #Subset data frame
    d <- df[, colvec]
    
    #Initialize empty vector for return
    ret <- c()
    
    for(i in 1:length(colvec)){
        
        #Only progress if column is numeric
        if(is.numeric(d[, i][[1]])){

            sumvec <- negorout_ind(d[, i][[1]])
            
            #If any value is an outlier or negative, cbind the vector
            if(sum(sumvec, na.rm = TRUE) > 0){
                
                ret <- cbind(ret, sumvec) 
                
                #Rename the right-most column to be equal to the variable name
                colnames(ret)[ncol(ret)] <- colvec[i]
                }
            else{}
            
        }
        #If column is not numeric, do nothing
        else{}
    }
    
    return(ret)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: checknegorout()
# Arguments:
#   df - a data frame
#   m - a matrix returned by negorout()
# Returns: a list of vectors containing values identified as negative or outlier
# Description: Uses the matrix returned by negorout() to subset the vector
#   and show the actual values that are being flagged as negatives or outliers.
#-----------------------------------------------------------------------------#
checknegorout <- function(df, m) {
    
    #Initialize empty list to return
    lst <- list()
    
    for(i in 1:ncol(m)){
        
        #Create a boolean vector that is true at indices for neg / outliers
        outlierindices <- which(m[, i] == 1)
        
        #Subset the vector based on the boolean vector
        vec <- bb[, colnames(m)[i]][[1]][outlierindices]
        
        #Add the variable name to the front of the vector
        #It's not pretty, but it works
        vec <- c(colnames(m)[i], vec)
        
        #Add the list into the list
        lst <- append(lst, list(vec))
        
    }
    
    return(lst)
}
```


```{r}
#-----------------------------------------------------------------------------#
# Function Name: checkzeroorone()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a vector of variable names that have values other than 0 or 1
# Description: This function is intended to be used only to check dummy 
#   variables with values of 0 or 1. It subsets the variable vector to only
#   include values that have values other than 0 or 1, and if the length of this
#   vector is greater than 0, it returns the name of the vector
#-----------------------------------------------------------------------------#
checkzeroorone <- function(df, vec){
    #Subset the vector
    d <- df[, vec]
    
    #Initialize return vector
    ret <- c() 
    for(i in 1:length(vec)) {
        
        #Store subsetted vector with values other than 0 or 1
        check <- d[, i][!(d[, i] == 0 | d[, i] == 1)]
        
        #If vector has any values, add variable name to returned vector
        if(length(check) > 0){
            ret <- c(ret, names(d)[i])
        }
        else{}
    }
    
    return(ret)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: checkzerototwo()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a vector of variable names that have values other than 0 or 3
# Description: This function is intended to be used only to check dummy 
#   variables with values of 0 or 3. It subsets the variable vector to only
#   include values that have values other than 0 or 3, and if the length of this
#   vector is greater than 0, it returns the name of the vector
#-----------------------------------------------------------------------------#
checkzerototwo <- function(df, vec){
    #Subset the vector
    d <- df[, vec]
    
    #Initialize return vector
    ret <- c() 
    for(i in 1:length(vec)) {
        
        #Store subsetted vector with values other than 0 or 1
        check <- d[, i][!(d[, i] == 0 | 
                              d[, i] == 1 |
                              d[, i] == 2)]
        
        #If vector has any values, add variable name to returned vector
        if(length(check) > 0){
            ret <- c(ret, names(d)[i])
        }
        else{}
    }
    
    return(ret)
}
```

```{r}
#-----------------------------------------------------------------------------#
# Function Name: checkzerotothree()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a vector of variable names that have values other than 0 or 3
# Description: This function is intended to be used only to check dummy 
#   variables with values of 0 or 3. It subsets the variable vector to only
#   include values that have values other than 0 or 3, and if the length of this
#   vector is greater than 0, it returns the name of the vector
#-----------------------------------------------------------------------------#
checkzerotothree <- function(df, vec){
    #Subset the vector
    d <- df[, vec]
    
    #Initialize return vector
    ret <- c() 
    for(i in 1:length(vec)) {
        
        #Store subsetted vector with values other than 0 or 1
        check <- d[, i][!(d[, i] == 0 | 
                              d[, i] == 1 |
                              d[, i] == 2 |
                              d[, i] == 3)]
        
        #If vector has any values, add variable name to returned vector
        if(length(check) > 0){
            ret <- c(ret, names(d)[i])
        }
        else{}
    }
    
    return(ret)
}
```


```{r}
#-----------------------------------------------------------------------------#
# Function Name: factorize()
# Arguments:
#   df - a data frame
#   vec - a vector with the column names of dummy variables
# Returns: a data frame identical to df with all the listed variables factorized
# Description: applies factor() function to all variables listed in vec
#-----------------------------------------------------------------------------#

factorize <- function(df, vec){
    
    for(i in 1:length(vec)) {
        
        df[, vec[i]][[1]] <- factor(df[, vec[i]][[1]])
    }
    
    return(df)
}
```

### Section 1

Looking at the data dictionary that's provided on the [Tidy Tuesday github page](https://github.com/rfordatascience/tidytuesday/blob/main/data/2025/2025-08-26/readme.md) for this data set, it looks like basically everything is the right data type, with no dummy variables. As seen below, the proportion of NA values for this chunk is very low. 
```{r}
#List of column names for this chunk
c1 <- names(bb)[1:16]

head(bb %>% select(all_of(c1)), 10)
```

Examining the proportion of NA values, we see that the number of NA values in each column is relatively small. 
```{r}
propna(bb, c1)
```

Additionally, we see that only one column has an outlier or negative value - the variable for number of weeks at the number one ranking. 
```{r}
m <- negorout(bb, c1)

dim(m)

colnames(m)
```
When we examine which value that is:
```{r}

outlierindices <- which(m[, 1] == 1)

bb$weeks_at_number_one[outlierindices]
```
We see that 2 songs were held the top spot for 19 weeks. These songs were:
```{r}
bb$song[outlierindices]
```
Hilariously, I have heard both of these songs. It's interesting because these are both songs that were released within the past 10 years, and both had a very strong presence on TikTok specifically. Fortunately, there is a variable in this dataset that is somewhat related to that (associated_with_dance).

This chunk looks relatively good - it has few NA values, data is already the correct type, and the few outliers that are in this chunk look reasonable and plausible. The only other thing I'd like to do is generate a year variable and a generation variable. The reason I want to do this is because I have a theory that some of the variability in what kinds of songs that rise to the Billboard Top 100 number 1 spot are dependent on the generation. Baby boomers tend to have different music tastes than Gen Alpha, and I think this should be accounted for in the model. The easiest way to do this, in my opinion, is to increment the years into a variable that represents the generation that is dominating the entry-level workforce. For example, right now, that would be Gen Z - which, understandably, listens to songs like Old Town Road and A Bar Song (and apparently, they listen to them a lot). My theory is there is an interaction term with the generation and the genre - Boomers grew up on rock and roll, Gen Z grew up on post-ironic-post-modern rap. 

First, I'll extract the year from the date variable using the year() function, and then use case_when() to create different generations based on the years. The dates span from 1958 to 2025. I'm using [this](https://en.wikipedia.org/wiki/Generation#/media/File:Generation_timeline.svg) reference for the definition of generations in the Western world, and then I'll shift the years by 22 to match when these generations enter what I consider their peak years of cultural influence. 
```{r}
library(lubridate)


bb <- bb %>% mutate(generation = case_when(
    year(date) > 1940 & year(date) <= 1967 ~ "Silent Generation",
    year(date) > 1968 & year(date) <= 1986 ~ "Baby Boomers",
    year(date) > 1987 & year(date) <= 2002 ~ "Generation X",
    year(date) > 2003 & year(date) <= 2018 ~ "Millennials",
    year(date) > 2019 ~ "Gen Z",
    TRUE ~ NA
))

propna(bb, c("generation"))
```

You're welcome to disagree with me on how I've cut up the generations if you want. But the most popular song on June 6, 2008 was Viva La Vida by Coldplay. If you're telling me that's not firmly a Millennial anthem, I'm not really sure what to tell you.

One final thought for this section is how to handle repeat songs.

```{r}
length(unique(bb$song)) < nrow(bb)
```
As seen above, there are clearly repeats of song names. When we examine what songs these are and when they hit the charts
```{r}
bb %>% filter(song %in% bb[duplicated(bb$song), ]$song) %>% arrange(song)
```
Some of these are just songs that happen to have common titles - I have to imagine "Wild Wild West" by The Escape Club is slightly different from "Wild Wild West" by Will Smith ft. Dru Hill & Kool Moe Dee. Just a hunch. I'm electing to not remove any duplicate songs for now.


### Section 2
This section contains information mostly about the artist and the producer. There are a few dummy variables that I will factorize after checking the data quality. I won't write as much as I did above, partially since it's getting a little tiring for me, and partially because you've seen what I'm doing.
```{r}
c2 <- names(bb)[17:39]

propna(bb, c2)

#TODO: Remove Featured Artists and Talent Contestant

m <- negorout(bb, c2)

ncol(m)

#4 columns with outliers

colnames(m)

#The group named after non-lead singer value is mostly 0
#Anything with a value of 1 is getting flagged as an outlier, I'm not concerned
bb$group_named_after_non_lead_singer[which(m[, 1] == 1)]

#Same with posthumous - value is almost always 0
bb$posthumous[which(m[, 2] == 1)]

#Apparently someone was 78 when their song hit #1
bb$front_person_age[which(m[, 3] == 1)]

#Apparently this was Brenda Lee, whose song Rockin' Around the Christmas Tree
# released in 1958 hit the Billboard Hot 100 Number 1 in 2023. Cool! Also, she
# was alive to see it happen. Also cool!
bb[which(m[, 3]==1), ]

#Dummy variable which is intended to have values of 0, 1, 2, or 3
#Value of 3 is just rare, not concerning
bb$producer_male[which(m[, 4] == 1)]
```

Now I need to factorize all the dummy variables. While the function to check for negative values or outliers is helpful, I also want to make sure that only the correct levels are included for each variable. 
```{r}
#Choose the variables that are dummy variables
dummy01 <- c("multiple_lead_vocalists", "group_named_after_non_lead_singer",
             "posthumous", "artist_is_a_songwriter", "artist_is_only_songwriter",
             "artist_is_a_producer", "artist_is_only_producer", 
             "songwriter_is_a_producer")
dummy02 <- c("artist_white", "artist_black", "songwriter_white", 
             "producer_white")
dummy03 <- c("artist_male", "songwriter_male", "producer_male")

checkzeroorone(bb, dummy01)
checkzerototwo(bb, dummy02)
checkzerotothree(bb, dummy03)

#All values look good - now can factorize

dummy <- c(dummy01, dummy02, dummy03)
bb <- factorize(bb, dummy)
```

The only other thing I want to do is combine artist_white and artist_black into one variable - artist_race. I'm doing this because these variables are both related to artist race and are mutually exclusive - an artist cannot be both white and black. I've double checked this below - there are no entries where both artist_white and artist_black are both 1 for the same observation.

```{r}
bb %>% filter(artist_white == 1 & artist_black == 1) %>% nrow()

bb <- bb %>% mutate(artist_race = case_when(
    artist_white == 1 ~ 1,
    artist_black == 2 ~ 2, 
    TRUE ~ 3, #To represent mixed race(s)
))

bb$artist_race <- factor(bb$artist_race)
```


### Section 3

Everything between the previous section and the section after this, which is all dummy variables for whether an instrument appears in a song. 
```{r}
c3 <-names(bb)[40:48]

bb %>% select(all_of(c3)) %>% head()

#Loudness is all negative, I'll just check for outliers by hand

#Very few NA values
propna(bb, c3)

#Remove loudness since it's all negative values
negorout(bb, c3[-8])
#No negative or outlier values

#Looks like there are some extreme values, but seems reasonable and possible
boxplot(bb$loudness_d_b)
```

```{r}
#Just some extra EDA
g <- ggplot(data = bb, aes(x = time_signature)) + geom_bar() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
#Over 90% of songs are in 4/4, I'm not going to clean this data further
g

g <- ggplot(data = bb %>% group_by(keys) %>% summarize(count = n()) %>% filter(count > 5), 
            aes(x = keys, y = count)) + geom_col() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
g

#Surprised that so many songs in the minor key are in here
#I'll make a variable for major or minor key

grepl("m", bb$keys)

bb <- bb %>% mutate(major_or_minor = case_when(
    
    #Ends in a minor key
    grepl("m$", keys) ~ "minor",
    
    is.na(keys) ~ NA,
    TRUE ~ "major"
))

#TODO: Create a variable for key by frequency?

g <- ggplot(data = bb, aes(x = major_or_minor)) + geom_bar()
g
```
Factorizing the appropriate variables from this section:
```{r}
bb$major_or_minor <- factor(bb$major_or_minor)

```

### Section 4

```{r}
c4 <- names(bb)[49:73]

propna(bb, c4) #Wow. All values for all variables

m <- negorout(bb, c4) #16 variables have at least one negative value or outlier
                      #Use a function to figure out what each value is

checknegorout(bb, m) #All values are 1, indicating that 1 is an outlier
                     #These instruments are likely so rare

#Confirm with histograms

par(mfrow = c(4, 4),
    mar = c(4, 4, 2, 1),
    oma = c(0, 0, 2, 0))

with(bb, {
    
    for(i in 1:ncol(m)){
        
        #Plot a histogram
        hist(bb[, colnames(m)[1]][[1]], main = colnames(m)[i], xlab = "")
        
    }
})

#All of these plots have very few 1s 

#TODO: Delete this columns since they won't add anything to the analysis
```
These are all dummy variables, which should have values 0 or 1. I'll use a function to quickly parse through and see if any have values that are not zero or one
```{r}
checkzeroorone(bb, names(bb)[49:73])

#Nice, all zeros or ones

bb <- factorize(bb, names(bb)[49:73])
```
### Section 5
```{r}
c5 <- names(bb)[74:94]

propna(bb, c5)
#Sound effects has 94% of values as NA - NA likely represents no sound effects
#TODO: Remove sound_effects since it's not doing much for me
#Remaining columns are all relatively NA free

m <- negorout(bb, c5)

colnames(m)

checknegorout(bb, m)
#Some of these look like they're outliers because they have values of either
# 0 or 1, and 1 is just rare

#Others seem like they might be actual outliers, specifically for song length
# and intro length

hist(bb$rap_verse_in_a_non_rap_song)
summary(bb$rap_verse_in_a_non_rap_song) # 1 is just a rare value

hist(bb$length_sec)
bb %>% filter(length_sec > 500) %>% head()
#After googling, both of these songs and their lengths are correct

hist(bb$instrumental)
summary(bb$instrumental) #1 is just a rare value

hist(bb$instrumental_length_sec)
bb %>% filter(instrumental_length_sec > 200) %>% 
    select(song, artist, instrumental_length_sec) %>% head()

#335 seconds is "Fly, Robin, Fly" which has only 6 words - "Fly, Robin, Fly,
# up, up to the sky." Why this was the number 1 song at any point is beyond me

#254 seconds is "The Hustle" by Van McCoy, which actually kind of slaps
#The other songs with long instrumentals also look correct

hist(bb$intro_length_sec)
bb %>% filter(intro_length_sec > 100) %>% 
    select(song, artist, intro_length_sec) %>% head()

#"Theme from Shaft" is truly 109 seconds of an intro
#"Papa Was a Rollin' Stone" is also 115 seconds of an intro
# Both look correct

hist(bb$free_time_vocal_introduction)
summary(bb$free_time_vocal_introduction) # 1 is just a rare value

hist(bb$foreign_language)
summary(bb$foreign_language) # 1 is just a rare value

#Checked all outliers / negative values, looks good to me

#Need to check all factor levels

dummy <- c5[-c(1, 2, 4, 6, 7, 16, 17)]

checkzeroorone(bb, dummy) #everything has a value of 0 or 1

bb <- factorize(bb, dummy)

#TODO: Think more about song structure - should I factorize?
```


### Section 6

I grouped off this section of variables since I feel like it has a lot to do with media:
```{r}
c6 <- names(bb)[95:105]

propna(bb, c6)

#The "featured_in" variables are almost all NA
#NA likely represents that it was not featured in a piece of media

m <- negorout(bb, c6)
colnames(m)

checknegorout(bb, m)

#The unusual values are all 1, likely indicating that the value is rare
#Check each individually

hist(bb$written_for_a_play)
summary(bb$written_for_a_play)

hist(bb$written_for_a_t_v_show)
summary(bb$written_for_a_t_v_show)

hist(bb$associated_with_dance)
summary(bb$associated_with_dance)

hist(bb$topped_the_charts_by_multiple_artist)
summary(bb$topped_the_charts_by_multiple_artist)

hist(bb$eurovision_entry)
summary(bb$eurovision_entry)

#All the "outlier" values are reasonable
```
I think that, particularly for more recent years, having a song be written for or featured in a piece of media has a large impact. However, the issue with this data is that it's so spread out - there are very few entries for being featured in a movie, for being featured in a play, etc. I'm going to combine them all into one variable called media to indicate if they were written for or featured in a piece of popular media at the time. 

First, I'll convert all of the character variables into dummy variables to indicate whether or not they were featured in a piece of media, rather than what piece of media they were featured in, since that will be more helpful for our analysis
```{r}
bb <- bb %>% mutate(featured_in_a_then_contemporary_play = case_when(
    !is.na(featured_in_a_then_contemporary_play) ~ 1,
    TRUE ~ 0
))

bb <- bb %>% mutate(featured_in_a_then_contemporary_film = case_when(
    !is.na(featured_in_a_then_contemporary_film) ~ 1,
    TRUE ~ 0
))

bb <- bb %>% mutate(featured_in_a_then_contemporary_t_v_show = case_when(
    !is.na(featured_in_a_then_contemporary_t_v_show) ~ 1,
    TRUE ~ 0
))

#Combine them all into a featured variable

bb <- bb %>% mutate(featured = case_when(
    (featured_in_a_then_contemporary_play == 1 |
         featured_in_a_then_contemporary_film == 1 |
         featured_in_a_then_contemporary_t_v_show == 1) ~ 1,
    TRUE ~ 0
))

#Check that the written_for variables have only 0 or 1
checkzeroorone(bb, c("written_for_a_play", "written_for_a_film", 
                     "written_for_a_t_v_show"))

#Create a combined written_for variable

bb <- bb %>% mutate(written_for = case_when(
    (written_for_a_play == 1 |
         written_for_a_film == 1 |
         written_for_a_t_v_show == 1) ~ 1,
    TRUE ~ 0
))

#Create a combined media variable
bb <- bb %>% mutate(media = case_when(
    featured == 1 | written_for_a_play == 1 ~ 1,
    TRUE ~ 0
))

#Check the remaining factor variables
checkzeroorone(bb, c("associated_with_dance", "topped_the_charts_by_multiple_artist",
                     "double_a_side", "eurovision_entry"))

#Double A side is not 0 or 1
table(bb$double_a_side) #Ah. It lists the song name. Which is stated in the dd

#Factorize all relevant variables

bb <- factorize(bb, c("associated_with_dance", "topped_the_charts_by_multiple_artist",
                "eurovision_entry", "generation", "featured", "written_for", 
                "media"))
```

Ok. All of my data is clean now. I'm now going to remove any columns that I've flagged with TODOs since they're not going to add any value to my data analysis.

The list of variables I'm going to remove is:
- featured_artists
- talent_contestant
- all of those random instruments (contained in negorout(bb, c4))
- sound effects
- featured_in_a_then_contemporary_play
- featured_in_a_then_contemporary_film
- featured_in_a_then_contemporary_t_v_show
- written_for_a_play
- written_for_a_film
- written_for_a_t_v_show
- artist_white
- artist_black

```{r}
m <- negorout(bb, c4)

removenames <- c("featured_artists", 
                 "talent_contestant", 
                 "sound_effects",
                 "featured_in_a_then_contemporary_play", 
                 "featured_in_a_then_contemporary_film",
                 "featured_in_a_then_contemporary_t_v_show",
                 "written_for_a_play",
                 "written_for_a_film",
                 "written_for_a_t_v_show",
                 "artist_white",
                 "artist_black",
                 colnames(m))

bb <- bb %>% select(-(all_of(removenames)))

```

# Exploratory Data Analysis
Ok. For the fun stuff now. I have exactly 100 variables - I now need to investigate the relationship between each (or most) of these variables with the outcome of Weeks at Number 1

Starting with the ratings - there are 3 ratings from 3 judges, and the sample mean of those ratings. Let's take a look at those now:

```{r}

#Change plot to be 2x2
par(mfrow = c(2, 2))

with(bb, {hist(bb$rating_1, main = "Rating 1", xlab = "")
    hist(bb$rating_2, main = "Rating 2", xlab = "")
    hist(bb$rating_3, main = "Rating 3", xlab = "")
    hist(bb$overall_rating, main = "Overall Rating", xlab = "")
    })

```
Interestingly, it looks the median of rating 3 tends to be higher than the others. I'm actually curious if it's significantly different. I'll use the Kruskal-Wallis test since this is ordinal data rather than pure numeric data. 

```{r}
median(bb$rating_1)
median(bb$rating_3)
kruskal.test(bb$rating_3, bb$rating_1)
```
That's so interesting. Whoever Judge 3 is, they seem to be a bit nicer than Judge 1 at least.

Regardless, it looks like the overall rating is a better measure, since it follows the same distribution but is a composite of multiple ratings. 

```{r}
g <- ggplot(data = bb, aes(x = overall_rating, y = weeks_at_number_one)) + 
    geom_point(position = "jitter", alpha = 0.3, pch = 1)  + geom_smooth(method = "lm")
g
```
The relationship doesn't look as strong as I was expecting, but there's a clear non-zero trend that feels like it will explain some variability in the outcome. We should include it in our model.

Divisiveness is kind of interesting, I wonder what the distribution looks like:
```{r}
hist(bb$divisiveness) #Unsurprisingly, most songs are not that divisive

g <- ggplot(data = bb, aes(x = divisiveness, y = weeks_at_number_one)) + 
    geom_point(position = "jitter", alpha = 0.3, pch = 1)  + geom_smooth(method = "lm")
g
```
The relationship between divisiveness and weeks at number 1 is pretty weak - I'm going to elect to not include it in my model.

I can't imagine label or parent_label are going to make a significant difference in the analysis, but I'll check regardless:
```{r}
g <- ggplot(data = bb, aes(x = label)) + geom_bar()
g

#There are a few labels that are dominating, let's isolate them

bb %>% group_by(label) %>% summarize(count = n()) %>% filter(count > 5) %>% 
    arrange(desc(count))

#What does the parent_label look like?
bb %>% group_by(parent_label) %>% summarize(count = n()) %>% filter(count > 5) %>% 
    arrange(desc(count))

#It looks like label is consolidated, but parent_label is even more consolidated
#The top 5 parent labels account for almost 50% of all songs
```
The top 5 parent labels (Warner Bros, Sony, Vivendi, EMI, and CBS) account for almost 50% of all songs that have reached number 1 on the Billboard 100. I'm going to consolidate them into a variable called toplabel
```{r}
bb <- bb %>% mutate(toplabel = case_when(
    parent_label == "Warner Bros." | parent_label == "Sony" | 
        parent_label == "Vivendi" | parent_label == "EMI" |
        parent_label == "CBS" ~ 1,
    is.na(parent_label) ~ NA_real_,
    TRUE ~ 0
))

bb$toplabel <- factor(bb$toplabel)

#Writing out the whole variable name for the weeks at number 1 is annoying
#I'm going to rename it weeks

bb <- bb %>% rename(weeks = weeks_at_number_one)

g <- ggplot(data = bb, aes(x = toplabel, y = weeks)) + geom_boxplot()
g

#Surprisingly, it actually doesn't seem to make that much of a difference

kruskal.test(bb$weeks ~ bb$toplabel)
```
The Kruskal Wallis test does not reach significance with an alpha of 0.5, but it is close. The fact that the medians are so close makes me inclined to not include this in our final model.

Let's look at genre, which I'm sure will be important:
```{r}
table(bb$cdr_genre)

#TODO: consolidate genres

table(bb$discogs_genre)

#The style variables are all very different
```
The discogs genre is much more specific, but for the purposes of grouping it into a genre variable, it's much less useful. The CDR genre variable is a bit broader, which makes it easier to group things together. We'll only include the CDR genre - I'm going to include genre in the model regardless, since I assume it has to have a strong impact on the rankings.

```{r}
table(bb$cdr_genre)
```
I can see that there are variables that have very few entries, like Polka, but other genres like Pop are well represented here. For the sake of making reasonable groups, I'll choose the 6 largest genres, and combine the rest into a fifth variable of "other" (sorry. I've recently become more partial to Folk / Country music).
```{r}
bb %>% group_by(cdr_genre) %>% summarize(count = n()) %>% arrange(desc(count))

bb <- bb %>% mutate(genre = case_when(
    cdr_genre != "Pop" & cdr_genre != "Rock" & cdr_genre != "Funk/Soul" &
        cdr_genre != "Electronic/Dance" & cdr_genre != "Hip Hop" &
        cdr_genre != "Folk/Country" ~ "Other",
    is.na(cdr_genre) ~ NA,
    TRUE ~ cdr_genre
    
))
```

Hmmm. I just now saw that there are 88 NA values for genre. That's a little more than I was expecting. 
```{r}

```

